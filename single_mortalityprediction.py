# -*- coding: utf-8 -*-
"""Single_MortalityPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1svlXBLmRYJVMB5mdbggTrGPMuOW4Fqal
"""

import pandas as pd
import numpy as np
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import train_test_split, GroupKFold
from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score, precision_recall_curve
import lightgbm as lgb
import xgboost as xgb
from sklearn.ensemble import StackingClassifier, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
import re
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
import pandas as pd

drive.mount('/content/drive', force_remount=True)

import pickle
import pandas as pd
import numpy as np
import re

def add_mortality_prediction_for_patient(data_path, patient_id, model_path, output_path=None):
    """
    Predicts 90-day mortality for a specified patient ID and adds it to the dataset.

    Parameters:
    -----------
    data_path : str
        Path to the original data file
    patient_id : int
        ICU admission ID of the patient to predict
    model_path : str
        Path to the mortality prediction model file
    output_path : str, optional
        Path to save the results. If None, does not save

    Returns:
    --------
    tuple
        (mortality prediction probability, mortality prediction label (0 or 1), updated dataframe)
    """
    raw_data = pd.read_csv(data_path)

    patient_data = raw_data[raw_data['icustayid'] == patient_id]

    if len(patient_data) == 0:
        print(f"Error: Patient ID {patient_id} not found in the dataset")
        return None, None, raw_data

    with open(model_path, 'rb') as f:
        model = pickle.load(f)

    aggregated_data = aggregate_patient_data(patient_data)
    cleaned_data = clean_feature_names(aggregated_data)

    X = cleaned_data

    if hasattr(model, 'feature_names_in_'):
        required_features = model.feature_names_in_
    elif hasattr(model, '_feature_name'):
        required_features = model._feature_name
    else:
        required_features = []

    if len(required_features) > 0:
        missing_features = set(required_features) - set(X.columns)
        print(f"Missing {len(missing_features)} features")

        for feature in missing_features:
            X[feature] = 0

        extra_features = set(X.columns) - set(required_features)
        if extra_features:
            X = X.drop(columns=list(extra_features))

        X = X[required_features]

    try:
        mortality_prob = model.predict_proba(X)[0][1]
        mortality_label = 1 if mortality_prob >= 0.5 else 0
        print(f"Patient {patient_id}: Mortality prediction = {mortality_label} (Probability: {mortality_prob:.2%})")
    except Exception as e:
        print(f"Error predicting for patient {patient_id}: {e}")
        mortality_prob = 0
        mortality_label = 0

    if 'mortality_90d' not in raw_data.columns:
        raw_data['mortality_90d'] = 0

    raw_data.loc[raw_data['icustayid'] == patient_id, 'mortality_90d'] = mortality_label

    if output_path:
        raw_data.to_csv(output_path, index=False)
        print(f"Saved dataset with mortality prediction to {output_path}")

    return mortality_prob, mortality_label, raw_data

def aggregate_patient_data(df):
    columns = df.columns.tolist()

    agg_dict = {}

    numeric_columns = df.select_dtypes(include=['number']).columns
    for col in numeric_columns:
        if col != 'icustayid':
            agg_dict[col] = ['mean', 'max', 'min', 'std']

    if 'mortality_90d' in columns:
        agg_dict['mortality_90d'] = 'max'

    if 'charttime' in columns:
        agg_dict['charttime'] = 'count'

    agg_df = df.groupby('icustayid').agg(agg_dict)

    agg_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in agg_df.columns]

    return agg_df

def clean_feature_names(df):
    clean_df = df.copy()

    clean_columns = {}
    for col in clean_df.columns:
        new_col = re.sub(r'[^\w\s_]', '', col)
        new_col = re.sub(r'\s+', '_', new_col)
        clean_columns[col] = new_col

    clean_df = clean_df.rename(columns=clean_columns)

    return clean_df

if __name__ == "__main__":
    """Change Here"""


    data_path = '/content/drive/MyDrive/project2/AI_agent_test_sepsis_features.csv'
    patient_id = int(input("Enter patient ID to predict: "))
    model_path = '/content/Final_70_lightgbm_model.pkl'

    # Save output file option
    save_output = input("Do you want to save the results to a file? (y/n): ").lower() == 'y'
    output_path = None
    if save_output:
        output_path = input("Enter the file path to save: ")

    # Add mortality prediction to patient data
    mortality_prob, mortality_label, updated_data = add_mortality_prediction_for_patient(
        data_path, patient_id, model_path, output_path
    )

    # Print result summary
    if mortality_prob is not None:
        print("\n========== Prediction Result Summary ==========")
        print(f"Patient ID: {patient_id}")
        print(f"Death ratio: {mortality_prob:.2%}")
        print(f"Death prediction: {'Yes' if mortality_label == 1 else 'No'}")
        print("==============================================")