{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMP4uv_B1PRZ"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/project2/AI_agent_train_sepsis.csv'\n",
        "\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "lB0v055O1QVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split, GroupKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score, precision_recall_curve\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "QG084j_G1Rls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if 'mortality_90d' in data.columns:\n",
        "    value_counts = data['mortality_90d'].value_counts()\n",
        "    print(\"mortality_90d 값 분포:\")\n",
        "    print(value_counts)\n",
        "    print(\"\\n비율:\")\n",
        "    print(data['mortality_90d'].value_counts(normalize=True) * 100, \"%\")\n",
        "else:\n",
        "    print(\"mortality_90d 컬럼이 데이터셋에 존재하지 않습니다.\")"
      ],
      "metadata": {
        "id": "aIqaO1Yp-mnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_patient_data(df):\n",
        "    numerical_cols = [col for col in df.columns if col not in ['mortality_90d', 'icustayid', 'charttime', 'bloc']]\n",
        "\n",
        "    agg_dict = {\n",
        "        'mortality_90d': 'first',\n",
        "    }\n",
        "\n",
        "    for col in numerical_cols:\n",
        "        if col == 'age':\n",
        "            agg_dict[col] = 'first'\n",
        "        else:\n",
        "            agg_dict[col] = ['mean', 'min', 'max', 'std', 'last']\n",
        "\n",
        "    agg_dict['charttime'] = 'count'\n",
        "\n",
        "    agg_df = df.groupby('icustayid').agg(agg_dict)\n",
        "\n",
        "    agg_df.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in agg_df.columns]\n",
        "\n",
        "    return agg_df\n",
        "\n",
        "patient_df = aggregate_patient_data(data)\n",
        "\n",
        "def clean_feature_names(df):\n",
        "    clean_df = df.copy()\n",
        "\n",
        "    clean_columns = {}\n",
        "    for col in clean_df.columns:\n",
        "        new_col = re.sub(r'[^\\w\\s_]', '', col)\n",
        "        new_col = re.sub(r'\\s+', '_', new_col)\n",
        "        clean_columns[col] = new_col\n",
        "\n",
        "    clean_df = clean_df.rename(columns=clean_columns)\n",
        "\n",
        "    return clean_df\n",
        "\n",
        "patient_df = clean_feature_names(patient_df)\n",
        "\n",
        "X = patient_df.drop('mortality_90d_first', axis=1)\n",
        "y = patient_df['mortality_90d_first']\n",
        "\n",
        "\n",
        "patient_ids = patient_df.index.unique().tolist()\n",
        "np.random.seed(42)\n",
        "np.random.shuffle(patient_ids)\n",
        "train_size = int(len(patient_ids) * 0.8)\n",
        "train_ids = patient_ids[:train_size]\n",
        "test_ids = patient_ids[train_size:]\n",
        "\n",
        "X_train = X.loc[train_ids]\n",
        "X_test = X.loc[test_ids]\n",
        "y_train = y.loc[train_ids]\n",
        "y_test = y.loc[test_ids]"
      ],
      "metadata": {
        "id": "VN9wmu1R1UUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision_curve, recall_curve, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
        "    f1_scores = 2 * precision_curve * recall_curve / (precision_curve + recall_curve + 1e-7)\n",
        "    optimal_idx = np.argmax(f1_scores)\n",
        "    optimal_threshold = thresholds[optimal_idx] if optimal_idx < len(thresholds) else 0.5\n",
        "\n",
        "    y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
        "\n",
        "    optimal_precision = precision_curve[optimal_idx]\n",
        "    optimal_recall = recall_curve[optimal_idx]\n",
        "    optimal_f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    return {\n",
        "        'AUC': auc,\n",
        "        'F1 Score': optimal_f1,\n",
        "        'Optimal Threshold': optimal_threshold,\n",
        "        'Predictions': y_pred,\n",
        "        'Probabilities': y_pred_proba,\n",
        "        'Optimal Precision': optimal_precision,\n",
        "        'Optimal Recall': optimal_recall,\n",
        "        'Precision Curve': precision_curve,\n",
        "        'Recall Curve': recall_curve\n",
        "    }\n",
        "\n",
        "models = {\n",
        "    'CatBoost': catboost_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'RandomForest': rf_model,\n",
        "    'Stacking': stacking_model\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Evaluating {name} model...\")\n",
        "    results[name] = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "print(\"\\nModel performance comparison (sorted by AUC):\")\n",
        "for name, metrics in sorted(results.items(), key=lambda x: x[1]['AUC'], reverse=True):\n",
        "    print(f\"{name}: Precision = {metrics['Optimal Precision']:.4f}, Recall = {metrics['Optimal Recall']:.4f}, F1 Score = {metrics['F1 Score']:.4f}, AUC = {metrics['AUC']:.4f}, Threshold = {metrics['Optimal Threshold']:.4f}\")\n",
        "\n",
        "print(\"\\nModel performance comparison (sorted by F1 Score):\")\n",
        "for name, metrics in sorted(results.items(), key=lambda x: x[1]['F1 Score'], reverse=True):\n",
        "    print(f\"{name}: F1 Score = {metrics['F1 Score']:.4f}, AUC = {metrics['AUC']:.4f}, Threshold = {metrics['Optimal Threshold']:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "auc_values = [metrics['AUC'] for name, metrics in results.items()]\n",
        "model_names = list(results.keys())\n",
        "\n",
        "sns.barplot(x=model_names, y=auc_values)\n",
        "plt.title('AUC Comparison')\n",
        "plt.ylim(0.7, 1.0)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "f1_values = [metrics['F1 Score'] for name, metrics in results.items()]\n",
        "\n",
        "sns.barplot(x=model_names, y=f1_values)\n",
        "plt.title('F1 Score Comparison')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E_2KKdsE1YxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "\n",
        "import pickle\n",
        "\n",
        "models_to_save = {\n",
        "    'catboost': catboost_model,\n",
        "    'lightgbm': lgb_model,\n",
        "    'xgboost': xgb_model,\n",
        "    'randomforest': rf_model,\n",
        "    'stacking': stacking_model\n",
        "}\n",
        "\n",
        "import os\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "\n",
        "for name, model in models_to_save.items():\n",
        "    with open(f'saved_models/{name}_model.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"{name} 모델이 saved_models/{name}_model.pkl에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "id": "q66nJwYR1u9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'CatBoost': catboost_model,\n",
        "    'LightGBM': lgb_model,\n",
        "    'XGBoost': xgb_model,\n",
        "    'RandomForest': rf_model,\n",
        "    'Stacking': stacking_model\n",
        "}\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "if 'feature_names' not in globals():\n",
        "    feature_names = X.columns.tolist()\n",
        "\n",
        "def analyze_shap_values(models, X_test, feature_names):\n",
        "    shap_values_dict = {}\n",
        "\n",
        "    n_samples = min(1000, X_test.shape[0])\n",
        "    X_sample = X_test.iloc[:n_samples]\n",
        "\n",
        "    for name, model in models.items():\n",
        "        print(f\"Calculating SHAP values for {name} model...\")\n",
        "        try:\n",
        "            explainer = shap.TreeExplainer(model)\n",
        "            shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "            if isinstance(shap_values, list):\n",
        "                if len(shap_values) > 1:\n",
        "                    shap_values = shap_values[1]\n",
        "\n",
        "            shap_values_dict[name] = {\n",
        "                'values': shap_values,\n",
        "                'explainer': explainer,\n",
        "                'data': X_sample\n",
        "            }\n",
        "            print(f\"Successfully calculated SHAP values for {name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating SHAP values for {name}: {e}\")\n",
        "\n",
        "    return shap_values_dict\n",
        "\n",
        "shap_values_dict = analyze_shap_values(models, X_test, feature_names)\n"
      ],
      "metadata": {
        "id": "aIpB3_2_-hCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if shap_values_dict:\n",
        "    for name, shap_data in shap_values_dict.items():\n",
        "        plt.close('all')\n",
        "        plt.figure(figsize=(12, 10))\n",
        "\n",
        "        try:\n",
        "            shap.summary_plot(\n",
        "                shap_data['values'],\n",
        "                shap_data['data'],\n",
        "                feature_names=feature_names,\n",
        "                max_display=10,\n",
        "                show=False\n",
        "            )\n",
        "            plt.title(f'SHAP Feature Impact - {name}', fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'shap_feature_impact_{name}.png', bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error plotting SHAP summary for {name}: {e}\")\n",
        "\n",
        "        try:\n",
        "            plt.figure(figsize=(20, 3))\n",
        "            sample_idx = 0\n",
        "\n",
        "            exp_value = shap_data['explainer'].expected_value\n",
        "            if isinstance(exp_value, list):\n",
        "                exp_value = exp_value[1]\n",
        "\n",
        "            shap.force_plot(\n",
        "                exp_value,\n",
        "                shap_data['values'][sample_idx, :],\n",
        "                shap_data['data'].iloc[sample_idx],\n",
        "                feature_names=feature_names,\n",
        "                matplotlib=True,\n",
        "                show=False\n",
        "            )\n",
        "            plt.title(f'SHAP Force Plot - Sample {sample_idx}', fontsize=14)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'shap_force_plot_{name}_sample_{sample_idx}.png', bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating force plot: {e}\")\n",
        "\n",
        "        mean_abs_shap = np.abs(shap_data['values']).mean(axis=0)\n",
        "        top_indices = np.argsort(-mean_abs_shap)[:5]\n",
        "\n",
        "        for idx in top_indices:\n",
        "            feature = feature_names[idx]\n",
        "            plt.close('all')\n",
        "            plt.figure(figsize=(10, 7))\n",
        "\n",
        "            try:\n",
        "\n",
        "                shap.dependence_plot(\n",
        "                    idx,\n",
        "                    shap_data['values'],\n",
        "                    shap_data['data'],\n",
        "                    feature_names=feature_names,\n",
        "                    interaction_index=None,\n",
        "                    show=False\n",
        "                )\n",
        "                plt.title(f'SHAP Dependence Plot - {feature}', fontsize=14)\n",
        "                plt.tight_layout()\n",
        "                plt.savefig(f'shap_dependence_{name}_{feature}.png', bbox_inches='tight')\n",
        "                plt.show()\n",
        "                plt.close()\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating dependence plot for {feature}: {e}\")\n",
        "else:\n",
        "    print(\"No SHAP values were calculated. Check for errors in the previous steps.\")"
      ],
      "metadata": {
        "id": "0SdmcRPr_FDG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}