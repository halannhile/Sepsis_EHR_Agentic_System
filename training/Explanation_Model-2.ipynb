{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cw4twHFK49tX"
      },
      "outputs": [],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "file_path = '/content/drive/MyDrive/project2/AI_agent_train_sepsis.csv'\n",
        "\n",
        "data = pd.read_csv(file_path)\n"
      ],
      "metadata": {
        "id": "OLyduXgz4_e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split, GroupKFold\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix, f1_score, precision_recall_curve\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "m3yC9D-35BVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "def load_data_and_model(data_path, model_path):\n",
        "    print(f\"Loading data from {data_path}...\")\n",
        "    data = pd.read_csv(data_path)\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    with open(model_path, 'rb') as f:\n",
        "        model = pickle.load(f)\n",
        "    return data, model\n",
        "\n",
        "\n",
        "def predict_mortality_for_patient(patient_id, data, model):\n",
        "\n",
        "    patient_data = data[data['icustayid'] == patient_id]\n",
        "\n",
        "    if len(patient_data) == 0:\n",
        "        print(f\"Error: Patient ID {patient_id} not found in the dataset\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    numerical_cols = [col for col in patient_data.columns if col not in ['mortality_90d', 'icustayid', 'charttime', 'bloc']]\n",
        "    agg_dict = {}\n",
        "\n",
        "    if 'mortality_90d' in patient_data.columns:\n",
        "        agg_dict['mortality_90d'] = 'first'\n",
        "\n",
        "    for col in numerical_cols:\n",
        "        if col == 'age':\n",
        "            agg_dict[col] = 'first'\n",
        "        else:\n",
        "            agg_dict[col] = ['mean', 'min', 'max', 'std', 'last']\n",
        "\n",
        "    if 'charttime' in patient_data.columns:\n",
        "        agg_dict['charttime'] = 'count'\n",
        "\n",
        "    aggregated_data = patient_data.groupby('icustayid').agg(agg_dict)\n",
        "\n",
        "    aggregated_data.columns = ['_'.join(col).strip() if isinstance(col, tuple) else col for col in aggregated_data.columns]\n",
        "\n",
        "    clean_df = aggregated_data.copy()\n",
        "    clean_columns = {}\n",
        "    for col in clean_df.columns:\n",
        "        new_col = re.sub(r'[^\\w\\s_]', '', col)\n",
        "        new_col = re.sub(r'\\s+', '_', new_col)\n",
        "        clean_columns[col] = new_col\n",
        "\n",
        "    cleaned_data = clean_df.rename(columns=clean_columns)\n",
        "\n",
        "    if 'mortality_90d_first' in cleaned_data.columns:\n",
        "        X = cleaned_data.drop('mortality_90d_first', axis=1)\n",
        "    else:\n",
        "        X = cleaned_data\n",
        "\n",
        "    if hasattr(model, 'feature_names_in_'):\n",
        "        required_features = model.feature_names_in_\n",
        "    elif hasattr(model, '_feature_name'):\n",
        "        required_features = model._feature_name\n",
        "    else:\n",
        "        required_features = []\n",
        "\n",
        "    if len(required_features) > 0:\n",
        "        missing_features = set(required_features) - set(X.columns)\n",
        "        print(f\"Missing {len(missing_features)} features\")\n",
        "\n",
        "        for feature in missing_features:\n",
        "            X[feature] = 0\n",
        "\n",
        "        extra_features = set(X.columns) - set(required_features)\n",
        "        if extra_features:\n",
        "            X = X.drop(columns=list(extra_features))\n",
        "\n",
        "        X = X[required_features]\n",
        "\n",
        "\n",
        "    try:\n",
        "        mortality_prob = model.predict_proba(X)[0][1]\n",
        "        mortality_label = 1 if mortality_prob >= 0.2112 else 0\n",
        "        print(f\"Patient {patient_id}: Mortality prediction = {mortality_label} (Probability: {mortality_prob:.2%})\")\n",
        "        return mortality_prob, mortality_label, X\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting for patient {patient_id}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LgcJLzgC5D7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_patient_specific_shap(patient_id, data, model):\n",
        "    print(f\"Calculating SHAP values specifically for patient {patient_id}...\")\n",
        "\n",
        "    mortality_prob, mortality_label, X = predict_mortality_for_patient(patient_id, data, model)\n",
        "\n",
        "    if X is None:\n",
        "        print(f\"Error: Failed to process data for patient {patient_id}\")\n",
        "        return None\n",
        "\n",
        "    feature_names = X.columns.tolist()\n",
        "\n",
        "    try:\n",
        "        if hasattr(model, 'set_params'):\n",
        "            print(\"Setting predict_disable_shape_check=True\")\n",
        "            model.set_params(predict_disable_shape_check=True)\n",
        "\n",
        "\n",
        "        print(\"Creating SHAP TreeExplainer...\")\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "\n",
        "        print(f\"Calculating SHAP values for patient {patient_id}...\")\n",
        "        shap_values = explainer.shap_values(X)\n",
        "\n",
        "        if isinstance(shap_values, list):\n",
        "            if len(shap_values) > 1:\n",
        "                print(\"Using positive class SHAP values (index 1)\")\n",
        "                shap_values = shap_values[1]\n",
        "            else:\n",
        "                print(\"Using available SHAP values (index 0)\")\n",
        "                shap_values = shap_values[0]\n",
        "\n",
        "        key_features = [\n",
        "            'age_first', 'BUN_last', 'output_4hourly_std', 'SOFA_mean',\n",
        "            'Weight_kg_mean', 'input_4hourly_last', 'mechvent_std',\n",
        "            'GCS_mean', 'SIRS_mean', 'Creatinine_min'\n",
        "        ]\n",
        "\n",
        "        patient_info = {}\n",
        "\n",
        "        for feature in key_features:\n",
        "\n",
        "            matched_feature = find_matching_feature(feature, feature_names)\n",
        "\n",
        "            if matched_feature:\n",
        "                try:\n",
        "                    feature_idx = feature_names.index(matched_feature)\n",
        "\n",
        "                    feature_value = X[matched_feature].values[0]\n",
        "\n",
        "                    shap_value = shap_values[0, feature_idx]\n",
        "\n",
        "                    patient_info[feature] = {\n",
        "                        'value': float(feature_value),\n",
        "                        'shap': float(shap_value),\n",
        "                        'impact': 'positive' if shap_value > 0 else 'negative'\n",
        "                    }\n",
        "                except Exception as e:\n",
        "                    print(f\"Error extracting SHAP data for feature {feature}: {e}\")\n",
        "\n",
        "                    print(f\"Feature {feature} not found or cannot calculate SHAP value\")\n",
        "            else:\n",
        "                print(f\"Warning: No matching feature found for {feature}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            base_value = explainer.expected_value\n",
        "            if isinstance(base_value, list):\n",
        "                base_value = base_value[1]\n",
        "            patient_info['base_value'] = float(base_value)\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting base_value: {e}\")\n",
        "            patient_info['base_value'] = 0.5\n",
        "\n",
        "        try:\n",
        "            total_shap = np.sum(shap_values[0])\n",
        "            patient_info['total_shap'] = float(total_shap)\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating total SHAP: {e}\")\n",
        "            patient_info['total_shap'] = 0.0\n",
        "\n",
        "        print(f\"Successfully calculated SHAP values for patient {patient_id}\")\n",
        "        return patient_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating SHAP values for patient {patient_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def find_matching_feature(target_feature, feature_names):\n",
        "\n",
        "    if target_feature in feature_names:\n",
        "        return target_feature\n",
        "\n",
        "\n",
        "\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "ckcc91EJvLtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def explain_mortality_with_gemini(patient_id, mortality_prob, patient_shap_data, api_key):\n",
        "\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "    feature_descriptions = {\n",
        "        'age_first': 'Patient\\'s age (first measurement)',\n",
        "        'BUN_last': 'Blood Urea Nitrogen (BUN) level (last measurement)',\n",
        "        'output_4hourly_std': 'Standard deviation of urine output measured every 4 hours',\n",
        "        'SOFA_mean': 'Mean value of Sequential Organ Failure Assessment (SOFA) score',\n",
        "        'Weight_kg_mean': 'Mean value of patient\\'s weight (kg)',\n",
        "        'input_4hourly_last': 'Fluid intake measured every 4 hours (last measurement)',\n",
        "        'mechvent_std': 'Standard deviation of mechanical ventilation usage',\n",
        "        'GCS_mean': 'Mean value of Glasgow Coma Scale (GCS) score',\n",
        "        'SIRS_mean': 'Mean value of Systemic Inflammatory Response Syndrome (SIRS) score',\n",
        "        'Creatinine_min': 'Minimum value of creatinine level',\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an AI medical assistant that analyzes ICU patient medical data to predict and explain the probability of death within 90 days.\n",
        "    Patient ID {patient_id} has a mortality probability of {mortality_prob:.1f}%.\n",
        "    This prediction comes from a machine learning model based on SHAP (SHapley Additive exPlanations) values.\n",
        "    SHAP values indicate whether each feature (patient's vital signs, clinical data, etc.) increases (positive) or decreases (negative) the risk of death.\n",
        "    Below are the main feature values for this patient and their corresponding SHAP values:\n",
        "    {json.dumps(patient_shap_data, indent=2)}\n",
        "    Feature descriptions:\n",
        "    {json.dumps(feature_descriptions, indent=2)}\n",
        "    Based on the above data, please answer the following questions:\n",
        "\n",
        "    What are the 3 most important factors increasing this patient's risk of death?\n",
        "    What are the 3 most important factors decreasing this patient's risk of death?\n",
        "    Explain medically why each factor has such an impact.\n",
        "    Summarize this patient's overall health status and risk factors.\n",
        "    Suggest what interventions or treatments might be effective in improving this patient's chances of survival.\n",
        "\n",
        "    Please provide a professional response that doctors and nurses can understand, while also explaining clearly so that the patient's family can understand\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-2.0-flash')\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating explanation with Gemini: {e}\")\n",
        "        return f\"\"\"\n",
        "        환자 ID {patient_id}의 사망 확률은 {mortality_prob:.1f}%로 예측됩니다.\n",
        "\n",
        "        Gemini API에서 오류가 발생하여 자세한 설명을 생성할 수 없습니다.\n",
        "        오류 메시지: {str(e)}\n",
        "\n",
        "        주요 특성과 SHAP 값을 참고하여 의료진과 상담하세요.\n",
        "        \"\"\"\n",
        "\n",
        "def mortality_explanation_agent(patient_id, data_path, model_path, gemini_api_key):\n",
        "    try:\n",
        "\n",
        "        data, model = load_data_and_model(data_path, model_path)\n",
        "\n",
        "        mortality_prob, mortality_label, _ = predict_mortality_for_patient(patient_id, data, model)\n",
        "        if mortality_prob is None:\n",
        "            return f\"환자 ID {patient_id}의 사망률을 예측할 수 없습니다.\"\n",
        "\n",
        "        print(\"Calculating SHAP values specifically for this patient...\")\n",
        "        patient_shap_data = calculate_patient_specific_shap(patient_id, data, model)\n",
        "\n",
        "        if patient_shap_data is None:\n",
        "            return f\"환자 ID {patient_id}의 SHAP 값을 계산할 수 없습니다.\"\n",
        "\n",
        "        explanation = explain_mortality_with_gemini(patient_id, mortality_prob * 100, patient_shap_data, gemini_api_key)\n",
        "\n",
        "        return explanation\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Critical error in mortality_explanation_agent: {e}\")\n",
        "        return f\"\"\"\n",
        "        환자 ID {patient_id}에 대한 사망률 예측 과정에서 오류가 발생했습니다.\n",
        "        오류 메시지: {str(e)}\n",
        "\n",
        "        오류가 반복될 경우 시스템 관리자에게 문의하세요.\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "ukmrrRHHvHJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    CHANGE HERE\n",
        "    \"\"\"\n",
        "    data_path = '/content/drive/MyDrive/project2/AI_agent_test_sepsis_features.csv'\n",
        "    model_path = '/content/Final_70_lightgbm_model.pkl'\n",
        "    gemini_api_key = 'AIzaSyDn1F2k4894S4bvT_SsPnSbH6cjt9Bu06U'\n",
        "\n",
        "    patient_id = int(input(\"Enter patient ID to analyze: \"))\n",
        "\n",
        "    explanation = mortality_explanation_agent(\n",
        "        patient_id=patient_id,\n",
        "        data_path=data_path,\n",
        "        model_path=model_path,\n",
        "        gemini_api_key=gemini_api_key\n",
        "    )\n",
        "\n",
        "    print(\"\\n========== Mortality Explanation ==========\")\n",
        "    print(explanation)\n",
        "    print(\"===========================================\")"
      ],
      "metadata": {
        "id": "1Gvwmo80vDE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}